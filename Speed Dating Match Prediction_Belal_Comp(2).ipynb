{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speed Dating Match Prediction Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Speed Dating Match Prediction steps:-\n",
    "    *   1- ✔️ Meme competition [optional]\n",
    "    *   2- ✔️ Problem Formulation\n",
    "    *   3- ✔️ Document your code\n",
    "    *   4- ✔️ Model Tuning and Documentation\n",
    "    *   5- ✔️ Answer some of questions (briefly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- ✔️ Meme competition [optional]:\n",
    "* Include/find a MEME that you liked related to data science/data mining/machine learning. You can upload yours here\n",
    "https://github.com/CISC-873/Information-2022/issues/1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- ✔️ Problem Formulation:\n",
    "* Define the problem. What is the input? What is the output? What data mining function is required? What could be the challenges? What is the impact? What is an ideal solution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the problem**\n",
    "\n",
    "`We need to predict the outcome of a specific speed dating session based on the profile of two people, so we can implement a recommendation system to better match people in speed dating events. but the given data has a lot of missing values that must be handled to perform the model well.`\n",
    "\n",
    "**What is the input?**\n",
    "\n",
    "`we have some features for each participant ,this will help us to know some information about Participants,and predict exactly`\n",
    "\n",
    "**What is the output?** \n",
    "\n",
    "`The output is which the two people matches or not matched based on the features.`\n",
    "\n",
    "**What data mining function is required?**\n",
    "* Data Cleaning or Cleansing \n",
    "    * 1) Import the required Python libraries\n",
    "    * 2) Read Data\n",
    "    * 3) Some feature engineering\n",
    "* Work with Missing Data\n",
    "    * 1)Check Missing Data\n",
    "        1. Transform missing values to Nan for unknown values.\n",
    "        2. Check NaN Values Count.\n",
    "    * 2) Drop Missing Data\n",
    "    * 3) Fill Missing data with Pandas\n",
    "        - For Numerical Data\n",
    "            * Mean\n",
    "            * Median\n",
    "            * Mode or Most frequent\n",
    "        - For Categorical Data\n",
    "            * Mode or Most frequent\n",
    "    * 4) Fill Missing data with Sklearn Imputer\n",
    "        - SimpleImputer\n",
    "            * Mean\n",
    "            * Median\n",
    "            * Mode or Most frequent\n",
    "        - KNNImputer\n",
    "* Outliers Handling\n",
    "* Data Split to Train and Test Sets\n",
    "* Data Preprocessing Project – Feature Scaling\n",
    "* Models that will be used:\n",
    "\n",
    "   1) **XGBClassifier** \n",
    "   \n",
    "   2) **GradientBoostingClassifier**\n",
    "   \n",
    "   3) **ExtraTreesClassifier**\n",
    "\n",
    "    \n",
    "`A binary classification function Will be used`\n",
    "\n",
    "**What could be the challenges?**\n",
    "*  `The data have alot of missing value should be handled` \n",
    "* `we should select best classifier for classify more accurate` \n",
    "* `use feature selection to know what is the important features can give us high predict`\n",
    "* `The implementation of preprocessing processes, selection of appropriate features to increase model performance and the accuracy of machine learning or data mining models are affected because of poor quality of data, are considered to be challenging.`\n",
    "* `The real dataset never comes clean. It consists lot of discrepancies in the dataset. So, we have to clean the dataset for further processing.`\n",
    "  \n",
    "**What is the impact?**\n",
    "\n",
    "`The recommendation system can select two person that perfectly match each other based on their answers in the application`\n",
    "   \n",
    "**What is an ideal solution?**\n",
    "\n",
    "`\n",
    "Handleing of  missing data perfectly and select the best hyperparameters that gives high performance\n",
    "in case of my trials i notice that the Xgbclassifier did this perfectly\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning or Cleansing\n",
    "\n",
    "* Whenever we have to work with a real world dataset, the first problem that we face is to clean it. The real world dataset never comes clean. It consists lot of discrepancies in the dataset. So, we have to clean the dataset for further processing.\n",
    "\n",
    "* Cleaning data is the process of preparing the dataset for analysis. It is very important because the accuracy of machine learning or data mining models are affected because of poor quality of data.\n",
    "\n",
    "* So, data scientists spend a large amount of their time cleaning the dataset and transform them into a format with which they can work with. In fact, data scientists spend 80% of their time cleaning the data.\n",
    "\n",
    "* A very common scenario is that the dataset contains missing values coded as NaN. Also, the missing values are coded in different ways. The dataset may contain negative or invalid values. It may contain outliers. It may be in the untidy format. All of these are examples of a messy dataset.\n",
    "\n",
    "* In this project, I present several useful ways to handle these discrepancies in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- ✔️ Document your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * 1- Import the required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings #handling warning \n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np #used for working with arrays\n",
    "import pandas as pd#Pandas is mainly used for data analysis\n",
    "# Used to visualize distribution, trends and relationships of variables(visualization)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.ma.core import array\n",
    "import matplotlib.pyplot as plt#is a cross-platform, data visualization and graphical plotting library\n",
    "from sklearn.pipeline import Pipeline #pipeline is a way to codify and automate the workflow\n",
    "from xgboost.sklearn import XGBClassifier #Model binary classification, XGBoost classifier - faster, more accurate version of sklearn's GradientBoostingClassifier\n",
    "from sklearn.impute import SimpleImputer #Imputation transformer for completing missing values.\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.compose import ColumnTransformer # used to transform column(s) separate from the rest of the feature space\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier # ensemble classifier, fits several decision trees on several parameter combinations (bagging)\n",
    "from sklearn.ensemble import GradientBoostingClassifier#Model for classification\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder #Standardize features by removing the mean and scaling to unit variance.\n",
    "# one hot encoding is essential process of converting the categorical to numeric\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV#Tuning the hyper-parameters\n",
    "# from sklearn.datasets import fetch_openml # fetches datasets from openml (i.e. iris dataset)\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have two datasets to import one for trainig and another for testing in csv formats \n",
    "Tr_df = pd.read_csv(\"train.csv\")# read train file \n",
    "Ts_df = pd.read_csv(\"test.csv\")#read test file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>...</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>372.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>331.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>357.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
       "0       0    3       2    14     18         2       2.0     14       12   \n",
       "1       1   14       1     3     10         2       NaN      8        8   \n",
       "2       1   14       1    13     10         8       8.0     10       10   \n",
       "3       1   38       2     9     20        18      13.0      6        7   \n",
       "4       1   24       2    14     20         6       6.0     20       17   \n",
       "\n",
       "     pid  ...  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
       "0  372.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
       "1   63.0  ...      8.0       8.0     7.0     8.0      NaN      NaN       NaN   \n",
       "2  331.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
       "3  200.0  ...      9.0       8.0     8.0     6.0      NaN      NaN       NaN   \n",
       "4  357.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
       "\n",
       "   fun5_3  amb5_3    id  \n",
       "0     NaN     NaN  2583  \n",
       "1     NaN     NaN  6830  \n",
       "2     NaN     NaN  4840  \n",
       "3     NaN     NaN  5508  \n",
       "4     NaN     NaN  4828  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will deal first with training data \n",
    "Tr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5909 entries, 0 to 5908\n",
      "Columns: 192 entries, gender to id\n",
      "dtypes: float64(173), int64(11), object(8)\n",
      "memory usage: 8.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Some informations of df\n",
    "Tr_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the data has 192 columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning or Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2469, 192)\n"
     ]
    }
   ],
   "source": [
    "Ts_df['match'] = 0 #add column match to test file before concat to make the test data the same size like train \n",
    "print(Ts_df.shape)#shape of test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will concat the train file with test file to make the preprocessing on the two together \n",
    "df = pd.concat([Tr_df,Ts_df],ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>...</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>attr5_3</th>\n",
       "      <th>sinc5_3</th>\n",
       "      <th>intel5_3</th>\n",
       "      <th>fun5_3</th>\n",
       "      <th>amb5_3</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>372.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>331.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>357.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
       "0       0    3       2    14     18         2       2.0     14       12   \n",
       "1       1   14       1     3     10         2       NaN      8        8   \n",
       "2       1   14       1    13     10         8       8.0     10       10   \n",
       "3       1   38       2     9     20        18      13.0      6        7   \n",
       "4       1   24       2    14     20         6       6.0     20       17   \n",
       "\n",
       "     pid  ...  sinc3_3  intel3_3  fun3_3  amb3_3  attr5_3  sinc5_3  intel5_3  \\\n",
       "0  372.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
       "1   63.0  ...      8.0       8.0     7.0     8.0      NaN      NaN       NaN   \n",
       "2  331.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
       "3  200.0  ...      9.0       8.0     8.0     6.0      NaN      NaN       NaN   \n",
       "4  357.0  ...      NaN       NaN     NaN     NaN      NaN      NaN       NaN   \n",
       "\n",
       "   fun5_3  amb5_3    id  \n",
       "0     NaN     NaN  2583  \n",
       "1     NaN     NaN  6830  \n",
       "2     NaN     NaN  4840  \n",
       "3     NaN     NaN  5508  \n",
       "4     NaN     NaN  4828  \n",
       "\n",
       "[5 rows x 192 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8378, 192)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # The shape of the test and train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender         0\n",
       "idg            0\n",
       "condtn         0\n",
       "wave           0\n",
       "round          0\n",
       "            ... \n",
       "sinc5_3     6362\n",
       "intel5_3    6362\n",
       "fun5_3      6362\n",
       "amb5_3      6362\n",
       "id             0\n",
       "Length: 192, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can notice that the data has lots of nulls so we need to deal with .\n",
    "#### Also we need to know the number of nulls in each columns and the highest columns which have nulls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null_vals</th>\n",
       "      <th>percent_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_in_3</th>\n",
       "      <td>7710</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>numdat_3</th>\n",
       "      <td>6882</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expnum</th>\n",
       "      <td>6578</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amb7_2</th>\n",
       "      <td>6423</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc7_2</th>\n",
       "      <td>6423</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shar2_3</th>\n",
       "      <td>6362</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun7_3</th>\n",
       "      <td>6362</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intel7_3</th>\n",
       "      <td>6362</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc7_3</th>\n",
       "      <td>6362</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr7_3</th>\n",
       "      <td>6362</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shar7_2</th>\n",
       "      <td>6404</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intel7_2</th>\n",
       "      <td>6394</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun7_2</th>\n",
       "      <td>6394</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shar7_3</th>\n",
       "      <td>6362</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr7_2</th>\n",
       "      <td>6394</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr5_3</th>\n",
       "      <td>6362</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc5_3</th>\n",
       "      <td>6362</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intel5_3</th>\n",
       "      <td>6362</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun5_3</th>\n",
       "      <td>6362</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amb5_3</th>\n",
       "      <td>6362</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amb7_3</th>\n",
       "      <td>6362</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amb2_3</th>\n",
       "      <td>5419</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr4_3</th>\n",
       "      <td>5419</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shar4_3</th>\n",
       "      <td>5419</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intel4_3</th>\n",
       "      <td>5419</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun4_3</th>\n",
       "      <td>5419</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amb4_3</th>\n",
       "      <td>5419</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun2_3</th>\n",
       "      <td>5419</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intel2_3</th>\n",
       "      <td>5419</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc2_3</th>\n",
       "      <td>5419</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc4_3</th>\n",
       "      <td>5419</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr2_3</th>\n",
       "      <td>5419</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mn_sat</th>\n",
       "      <td>5245</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuition</th>\n",
       "      <td>4795</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr1_3</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intel1_3</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shar1_3</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr3_3</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun3_3</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intel3_3</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amb1_3</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc3_3</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun1_3</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amb3_3</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sinc1_3</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_3</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you_call</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>them_cal</th>\n",
       "      <td>4404</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>attr3_s</th>\n",
       "      <td>4378</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amb3_s</th>\n",
       "      <td>4378</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Null_vals  percent_\n",
       "num_in_3       7710      92.0\n",
       "numdat_3       6882      82.0\n",
       "expnum         6578      79.0\n",
       "amb7_2         6423      77.0\n",
       "sinc7_2        6423      77.0\n",
       "shar2_3        6362      76.0\n",
       "fun7_3         6362      76.0\n",
       "intel7_3       6362      76.0\n",
       "sinc7_3        6362      76.0\n",
       "attr7_3        6362      76.0\n",
       "shar7_2        6404      76.0\n",
       "intel7_2       6394      76.0\n",
       "fun7_2         6394      76.0\n",
       "shar7_3        6362      76.0\n",
       "attr7_2        6394      76.0\n",
       "attr5_3        6362      76.0\n",
       "sinc5_3        6362      76.0\n",
       "intel5_3       6362      76.0\n",
       "fun5_3         6362      76.0\n",
       "amb5_3         6362      76.0\n",
       "amb7_3         6362      76.0\n",
       "amb2_3         5419      65.0\n",
       "attr4_3        5419      65.0\n",
       "shar4_3        5419      65.0\n",
       "intel4_3       5419      65.0\n",
       "fun4_3         5419      65.0\n",
       "amb4_3         5419      65.0\n",
       "fun2_3         5419      65.0\n",
       "intel2_3       5419      65.0\n",
       "sinc2_3        5419      65.0\n",
       "sinc4_3        5419      65.0\n",
       "attr2_3        5419      65.0\n",
       "mn_sat         5245      63.0\n",
       "tuition        4795      57.0\n",
       "attr1_3        4404      53.0\n",
       "intel1_3       4404      53.0\n",
       "shar1_3        4404      53.0\n",
       "attr3_3        4404      53.0\n",
       "fun3_3         4404      53.0\n",
       "intel3_3       4404      53.0\n",
       "amb1_3         4404      53.0\n",
       "sinc3_3        4404      53.0\n",
       "fun1_3         4404      53.0\n",
       "amb3_3         4404      53.0\n",
       "sinc1_3        4404      53.0\n",
       "date_3         4404      53.0\n",
       "you_call       4404      53.0\n",
       "them_cal       4404      53.0\n",
       "attr3_s        4378      52.0\n",
       "amb3_s         4378      52.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will return the first 50 columns that have null values\n",
    "Col_null_vals = pd.DataFrame(df.isnull().sum())\n",
    "Col_null_vals.columns = ['Null_vals'] # To name the columns which has the null values\n",
    "Col_null_vals['percent_'] = round(Col_null_vals['Null_vals'] / len(df.index), 2) * 100\n",
    "Col_null_vals.sort_values('percent_', ascending = False)[:50]#make dataframe and calc percent of null values for each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['mn_sat',\n",
       "  'expnum',\n",
       "  'attr7_2',\n",
       "  'sinc7_2',\n",
       "  'intel7_2',\n",
       "  'fun7_2',\n",
       "  'amb7_2',\n",
       "  'shar7_2',\n",
       "  'numdat_3',\n",
       "  'num_in_3',\n",
       "  'attr7_3',\n",
       "  'sinc7_3',\n",
       "  'intel7_3',\n",
       "  'fun7_3',\n",
       "  'amb7_3',\n",
       "  'shar7_3',\n",
       "  'attr4_3',\n",
       "  'sinc4_3',\n",
       "  'intel4_3',\n",
       "  'fun4_3',\n",
       "  'amb4_3',\n",
       "  'shar4_3',\n",
       "  'attr2_3',\n",
       "  'sinc2_3',\n",
       "  'intel2_3',\n",
       "  'fun2_3',\n",
       "  'amb2_3',\n",
       "  'shar2_3',\n",
       "  'attr5_3',\n",
       "  'sinc5_3',\n",
       "  'intel5_3',\n",
       "  'fun5_3',\n",
       "  'amb5_3'],\n",
       " 33)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will drop the columns which is bigger than 63\n",
    "index=[row for row in Col_null_vals.index if Col_null_vals.loc[row, 'percent_'] >= 63]\n",
    "index, len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=index) # We drop 33 columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Columns: 159 entries, gender to id\n",
      "dtypes: float64(141), int64(11), object(7)\n",
      "memory usage: 10.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>...</th>\n",
       "      <th>intel1_3</th>\n",
       "      <th>fun1_3</th>\n",
       "      <th>amb1_3</th>\n",
       "      <th>shar1_3</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>6532.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "      <td>8368.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>3974.000000</td>\n",
       "      <td>8378.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500597</td>\n",
       "      <td>17.327166</td>\n",
       "      <td>1.828837</td>\n",
       "      <td>11.350919</td>\n",
       "      <td>16.872046</td>\n",
       "      <td>9.042731</td>\n",
       "      <td>9.295775</td>\n",
       "      <td>8.927668</td>\n",
       "      <td>8.963595</td>\n",
       "      <td>283.863767</td>\n",
       "      <td>...</td>\n",
       "      <td>19.411346</td>\n",
       "      <td>16.233415</td>\n",
       "      <td>10.898075</td>\n",
       "      <td>12.699142</td>\n",
       "      <td>7.240312</td>\n",
       "      <td>8.093357</td>\n",
       "      <td>8.388777</td>\n",
       "      <td>7.658782</td>\n",
       "      <td>7.391545</td>\n",
       "      <td>4188.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500029</td>\n",
       "      <td>10.940735</td>\n",
       "      <td>0.376673</td>\n",
       "      <td>5.995903</td>\n",
       "      <td>4.358458</td>\n",
       "      <td>5.514939</td>\n",
       "      <td>5.650199</td>\n",
       "      <td>5.477009</td>\n",
       "      <td>5.491068</td>\n",
       "      <td>158.584899</td>\n",
       "      <td>...</td>\n",
       "      <td>6.124502</td>\n",
       "      <td>5.163777</td>\n",
       "      <td>5.900697</td>\n",
       "      <td>6.557041</td>\n",
       "      <td>1.576596</td>\n",
       "      <td>1.610309</td>\n",
       "      <td>1.459094</td>\n",
       "      <td>1.744670</td>\n",
       "      <td>1.961417</td>\n",
       "      <td>2418.664611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.670000</td>\n",
       "      <td>14.810000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2094.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>16.330000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>14.290000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4188.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>408.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>16.670000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6282.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8377.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            gender          idg       condtn         wave        round  \\\n",
       "count  8378.000000  8378.000000  8378.000000  8378.000000  8378.000000   \n",
       "mean      0.500597    17.327166     1.828837    11.350919    16.872046   \n",
       "std       0.500029    10.940735     0.376673     5.995903     4.358458   \n",
       "min       0.000000     1.000000     1.000000     1.000000     5.000000   \n",
       "25%       0.000000     8.000000     2.000000     7.000000    14.000000   \n",
       "50%       1.000000    16.000000     2.000000    11.000000    18.000000   \n",
       "75%       1.000000    26.000000     2.000000    15.000000    20.000000   \n",
       "max       1.000000    44.000000     2.000000    21.000000    22.000000   \n",
       "\n",
       "          position     positin1        order      partner          pid  ...  \\\n",
       "count  8378.000000  6532.000000  8378.000000  8378.000000  8368.000000  ...   \n",
       "mean      9.042731     9.295775     8.927668     8.963595   283.863767  ...   \n",
       "std       5.514939     5.650199     5.477009     5.491068   158.584899  ...   \n",
       "min       1.000000     1.000000     1.000000     1.000000     1.000000  ...   \n",
       "25%       4.000000     4.000000     4.000000     4.000000   154.000000  ...   \n",
       "50%       8.000000     9.000000     8.000000     8.000000   281.000000  ...   \n",
       "75%      13.000000    14.000000    13.000000    13.000000   408.000000  ...   \n",
       "max      22.000000    22.000000    22.000000    22.000000   552.000000  ...   \n",
       "\n",
       "          intel1_3       fun1_3       amb1_3      shar1_3      attr3_3  \\\n",
       "count  3974.000000  3974.000000  3974.000000  3974.000000  3974.000000   \n",
       "mean     19.411346    16.233415    10.898075    12.699142     7.240312   \n",
       "std       6.124502     5.163777     5.900697     6.557041     1.576596   \n",
       "min       0.000000     0.000000     0.000000     0.000000     2.000000   \n",
       "25%      16.670000    14.810000     5.000000    10.000000     7.000000   \n",
       "50%      20.000000    16.330000    10.000000    14.290000     7.000000   \n",
       "75%      20.000000    20.000000    15.000000    16.670000     8.000000   \n",
       "max      45.000000    30.000000    30.000000    55.000000    12.000000   \n",
       "\n",
       "           sinc3_3     intel3_3       fun3_3       amb3_3           id  \n",
       "count  3974.000000  3974.000000  3974.000000  3974.000000  8378.000000  \n",
       "mean      8.093357     8.388777     7.658782     7.391545  4188.500000  \n",
       "std       1.610309     1.459094     1.744670     1.961417  2418.664611  \n",
       "min       2.000000     3.000000     2.000000     1.000000     0.000000  \n",
       "25%       7.000000     8.000000     7.000000     6.000000  2094.250000  \n",
       "50%       8.000000     8.000000     8.000000     8.000000  4188.500000  \n",
       "75%       9.000000     9.000000     9.000000     9.000000  6282.750000  \n",
       "max      12.000000    12.000000    12.000000    12.000000  8377.000000  \n",
       "\n",
       "[8 rows x 152 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8378 entries, 2583 to 6691\n",
      "Columns: 158 entries, gender to amb3_3\n",
      "dtypes: float64(141), int64(10), object(7)\n",
      "memory usage: 10.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df = df.set_index('id') # we will make the id the index of the df \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After what we see in df.describe() the number of categorical columns are 152 and the total columns are 159, so there are 7 categorical columns since the describe function deals only with numerical columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>undergra</th>\n",
       "      <th>tuition</th>\n",
       "      <th>from</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>income</th>\n",
       "      <th>career</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>Ed.D. in higher education policy at TC</td>\n",
       "      <td>University of Michigan-Ann Arbor</td>\n",
       "      <td>21,645.00</td>\n",
       "      <td>Palo Alto, CA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>University President</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6830</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>2,021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Engineer or iBanker or consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4840</th>\n",
       "      <td>Urban Planning</td>\n",
       "      <td>Rizvi College of Architecture, Bombay University</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bombay, India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Real Estate Consulting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>International Affairs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>10,471</td>\n",
       "      <td>45,300.00</td>\n",
       "      <td>public service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>Business</td>\n",
       "      <td>Harvard College</td>\n",
       "      <td>26,019.00</td>\n",
       "      <td>Midwest USA</td>\n",
       "      <td>66,208</td>\n",
       "      <td>46,138.00</td>\n",
       "      <td>undecided</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7982</th>\n",
       "      <td>Neuroscience and Education</td>\n",
       "      <td>Columbia</td>\n",
       "      <td>26,908.00</td>\n",
       "      <td>Hong Kong</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Academic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>School Psychology</td>\n",
       "      <td>Bucknell University</td>\n",
       "      <td>25,335.00</td>\n",
       "      <td>Erie, PA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>school psychologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>Law</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>11,204</td>\n",
       "      <td>26,482.00</td>\n",
       "      <td>Intellectual Property Attorney</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>Mathematics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vestal</td>\n",
       "      <td>13,850</td>\n",
       "      <td>42,640.00</td>\n",
       "      <td>college professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6691</th>\n",
       "      <td>General management/finance</td>\n",
       "      <td>LUISS, Rome</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General management/consulting</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8378 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       field  \\\n",
       "id                                             \n",
       "2583  Ed.D. in higher education policy at TC   \n",
       "6830                             Engineering   \n",
       "4840                          Urban Planning   \n",
       "5508                   International Affairs   \n",
       "4828                                Business   \n",
       "...                                      ...   \n",
       "7982              Neuroscience and Education   \n",
       "7299                       School Psychology   \n",
       "1818                                     Law   \n",
       "937                              Mathematics   \n",
       "6691              General management/finance   \n",
       "\n",
       "                                              undergra    tuition  \\\n",
       "id                                                                  \n",
       "2583                  University of Michigan-Ann Arbor  21,645.00   \n",
       "6830                                               NaN        NaN   \n",
       "4840  Rizvi College of Architecture, Bombay University        NaN   \n",
       "5508                                               NaN        NaN   \n",
       "4828                                   Harvard College  26,019.00   \n",
       "...                                                ...        ...   \n",
       "7982                                          Columbia  26,908.00   \n",
       "7299                               Bucknell University  25,335.00   \n",
       "1818                                               NaN        NaN   \n",
       "937                                                NaN        NaN   \n",
       "6691                                       LUISS, Rome        NaN   \n",
       "\n",
       "                from zipcode     income                             career  \n",
       "id                                                                          \n",
       "2583   Palo Alto, CA     NaN        NaN               University President  \n",
       "6830      Boston, MA   2,021        NaN  Engineer or iBanker or consultant  \n",
       "4840   Bombay, India     NaN        NaN             Real Estate Consulting  \n",
       "5508  Washington, DC  10,471  45,300.00                     public service  \n",
       "4828     Midwest USA  66,208  46,138.00                          undecided  \n",
       "...              ...     ...        ...                                ...  \n",
       "7982       Hong Kong       0        NaN                           Academic  \n",
       "7299        Erie, PA     NaN        NaN                school psychologist  \n",
       "1818        Brooklyn  11,204  26,482.00     Intellectual Property Attorney  \n",
       "937           Vestal  13,850  42,640.00                  college professor  \n",
       "6691           Italy     136        NaN      General management/consulting  \n",
       "\n",
       "[8378 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cat_cols_selector = selector(dtype_include=object) # take an instance that select the cat cols \n",
    "# return list with the names of cat cols['field', 'undergra', 'tuition', 'from', 'zipcode', 'income', 'career']\n",
    "Cat_cols = Cat_cols_selector(df) \n",
    "df[Cat_cols] # To see the contant of these cols  and as we can see they are 7 cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtualization of the columns to take insights from them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For 'age' and 'age_o' columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE A FUNCTION THAT USED TO PLOT COLUM\n",
    "def Hist_Plot(column_name):\n",
    "  fig, ax = plt.subplots(figsize=(15, 8))\n",
    "  sns.countplot(column_name, data = df, order = df[column_name].value_counts().index, ax = ax)\n",
    "  ax.set(xlabel=column_name, ylabel='Count')\n",
    "  plt.xticks(rotation=45, ha='right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hist_Plot('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hist_Plot('age_o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From the above two, we notice that the age_o and age columns are the same, so we will drop one of them "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For 'field' and 'field_cd' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**field: field of study**\n",
    "\n",
    "**field_cd: field coded**\n",
    "-    1= Law \n",
    "-    2= Math\n",
    "-    3= Social Science, Psychologist \n",
    "-    4= Medical Science, Pharmaceuticals, and Bio Tech \n",
    "-    5= Engineering \n",
    "-    6= English/Creative Writing/ Journalism \n",
    "-    7= History/Religion/Philosophy \n",
    "-    8= Business/Econ/Finance \n",
    "-    9= Education, Academia \n",
    "-    10= Biological Sciences/Chemistry/Physics\n",
    "-    11= Social Work \n",
    "-    12= Undergrad/undecided \n",
    "-    13=Political Science/International Affairs \n",
    "-    14=Film\n",
    "-    15=Fine Arts/Arts Administration\n",
    "-    16=Languages\n",
    "-    17=Architecture\n",
    "-    18=Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the report, As we can see the 'field_cd' is the label encoding for the column 'field' so we can drop this column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For 'career ' and 'career_c' columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**career** What is your intended career?\n",
    "\n",
    "**career_c: career coded**\n",
    "- 1= Lawyer \n",
    "- 2= Academic/Research \n",
    "- 3= Psychologist \n",
    "- 4= Doctor/Medicine \n",
    "- 5=Engineer \n",
    "- 6= Creative Arts/Entertainment \n",
    "- 7= Banking/Consulting/Finance/Marketing/Business/CEO/Entrepreneur/Admin \n",
    "- 8= Real Estate \n",
    "- 9= International/Humanitarian Affairs \n",
    "- 10= Undecided \n",
    "- 11=Social Work\n",
    "- 12=Speech Pathology\n",
    "- 13=Politics\n",
    "- 14=Pro sports/Athletics\n",
    "- 15=Other\n",
    "- 16=Journalism\n",
    "- 17=Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the report, As we can see the 'career_c' is the label encoding for the column 'career' so we can drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop some selected columns \n",
    "# We don't drop the coded columns since the model can deal with numercial columns\n",
    "df = df.drop(columns=['field','career','age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8378 entries, 2583 to 6691\n",
      "Columns: 155 entries, gender to amb3_3\n",
      "dtypes: float64(140), int64(10), object(5)\n",
      "memory usage: 10.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deal with Categorical columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The category data type in pandas is a hybrid data type. It looks and behaves like a string in many instances but internally is represented by an array of integers. This allows the data to be sorted in a custom order and to more efficiently store the data.\n",
    "\n",
    "* At the end of the day why do we care about using categorical values? There are 3 main reasons:\n",
    "\n",
    "* We can define a custom sort order which can improve summarizing and reporting the data. In the example above, “X-Small” < “Small” < “Medium” < “Large” < “X-Large”. Alphabetical sorting would not be able to reproduce that order.\n",
    "* Some of the python visualization libraries can interpret the categorical data type to apply approrpiate statistical models or plot types.\n",
    "* Categorical data uses less memory which can lead to performance improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The simplest way to convert a column to a categorical type is to use astype('category') . We can use a loop to convert all the columns we care about using astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## categorical encoding of this cols except 'field' and 'career' we drop them\n",
    "cols_to_exclude = ['undergra', 'tuition', 'from', 'zipcode', 'income']\n",
    "for col in cols_to_exclude:\n",
    "        df[col] = df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8378 entries, 2583 to 6691\n",
      "Columns: 155 entries, gender to amb3_3\n",
      "dtypes: category(5), float64(140), int64(10)\n",
      "memory usage: 10.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5909, 155)\n",
      "2469\n",
      "(2469, 155)\n"
     ]
    }
   ],
   "source": [
    "train_data_index = Tr_df.shape[0] # it will return 5909 the number of trained data in the original csv file\n",
    "train_data_cleaned = df.iloc[:train_data_index] #Return the trained data \n",
    "train_data_cleaned_index = df.shape[0]\n",
    "print(train_data_cleaned.shape)\n",
    "test_data_index = Ts_df.shape[0]\n",
    "print(test_data_index)\n",
    "test_data_cleaned = df.iloc[train_data_index :]\n",
    "print(test_data_cleaned.shape)\n",
    "test_data_cleaned= test_data_cleaned.drop('match', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5909 entries, 2583 to 8149\n",
      "Columns: 155 entries, gender to amb3_3\n",
      "dtypes: category(5), float64(140), int64(10)\n",
      "memory usage: 6.9 MB\n"
     ]
    }
   ],
   "source": [
    "train_data_cleaned.info()#information for train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2469 entries, 934 to 6691\n",
      "Columns: 154 entries, gender to amb3_3\n",
      "dtypes: category(5), float64(140), int64(9)\n",
      "memory usage: 2.9 MB\n"
     ]
    }
   ],
   "source": [
    "test_data_cleaned.info()#information for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5909, 154)\n",
      "(5909,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>idg</th>\n",
       "      <th>condtn</th>\n",
       "      <th>wave</th>\n",
       "      <th>round</th>\n",
       "      <th>position</th>\n",
       "      <th>positin1</th>\n",
       "      <th>order</th>\n",
       "      <th>partner</th>\n",
       "      <th>pid</th>\n",
       "      <th>...</th>\n",
       "      <th>sinc1_3</th>\n",
       "      <th>intel1_3</th>\n",
       "      <th>fun1_3</th>\n",
       "      <th>amb1_3</th>\n",
       "      <th>shar1_3</th>\n",
       "      <th>attr3_3</th>\n",
       "      <th>sinc3_3</th>\n",
       "      <th>intel3_3</th>\n",
       "      <th>fun3_3</th>\n",
       "      <th>amb3_3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>372.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6830</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>63.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4840</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>331.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.37</td>\n",
       "      <td>18.37</td>\n",
       "      <td>18.37</td>\n",
       "      <td>14.29</td>\n",
       "      <td>14.29</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>357.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gender  idg  condtn  wave  round  position  positin1  order  partner  \\\n",
       "id                                                                           \n",
       "2583       0    3       2    14     18         2       2.0     14       12   \n",
       "6830       1   14       1     3     10         2       NaN      8        8   \n",
       "4840       1   14       1    13     10         8       8.0     10       10   \n",
       "5508       1   38       2     9     20        18      13.0      6        7   \n",
       "4828       1   24       2    14     20         6       6.0     20       17   \n",
       "\n",
       "        pid  ...  sinc1_3  intel1_3  fun1_3  amb1_3  shar1_3  attr3_3  \\\n",
       "id           ...                                                        \n",
       "2583  372.0  ...      NaN       NaN     NaN     NaN      NaN      NaN   \n",
       "6830   63.0  ...    20.00     15.00   20.00   10.00    15.00      6.0   \n",
       "4840  331.0  ...      NaN       NaN     NaN     NaN      NaN      NaN   \n",
       "5508  200.0  ...    18.37     18.37   18.37   14.29    14.29      8.0   \n",
       "4828  357.0  ...      NaN       NaN     NaN     NaN      NaN      NaN   \n",
       "\n",
       "      sinc3_3  intel3_3  fun3_3  amb3_3  \n",
       "id                                       \n",
       "2583      NaN       NaN     NaN     NaN  \n",
       "6830      8.0       8.0     7.0     8.0  \n",
       "4840      NaN       NaN     NaN     NaN  \n",
       "5508      9.0       8.0     8.0     6.0  \n",
       "4828      NaN       NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 154 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data_cleaned.iloc[:, :] #take an object from the data\n",
    "X = X.drop('match', axis=1)           \n",
    "Y = train_data_cleaned['match']# The class label\n",
    "print(X.shape) , print(Y.shape)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract numeric features and categorical features names\n",
    "Numeric_features = list(X.select_dtypes(include=['float64', 'int64']))\n",
    "Cat_features = list(X.select_dtypes(include=['category']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Models that will be used:\n",
    "\n",
    "   1) **XGBClassifier** \n",
    "       - Grid Search\n",
    "       - Bayesian Search\n",
    "       - Random Search\n",
    "   2) **GradientBoostingClassifier**\n",
    "       - Grid Search\n",
    "       - Bayesian Search\n",
    "       - Random Search\n",
    "   3) **ExtraTreesClassifier**\n",
    "       - Grid Search\n",
    "       - Bayesian Search\n",
    "       - Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- ✔️ Model Tuning and Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Searching Functions & CSV creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#___________________________CSV creator Function____________________________________________________________\n",
    "# This function which will be used to save the csv file \n",
    "def CSV_creator(model_name, obj_):\n",
    "    # prepare submission:\n",
    "    submission = pd.DataFrame()\n",
    "    submission['id'] = Ts_df['id']\n",
    "    submission['match'] = obj_.predict_proba(test_data_cleaned)[:,1]\n",
    "    submission.to_csv(f'_{model_name}.csv', index=False)\n",
    "                    \n",
    "#___________________________Grid Search Function____________________________________________________________\n",
    "# Create the grid search function which it will be used with three models to tune the hyperparameters                     \n",
    "def grid_search_fun(pipeline, parameters, model_name):\n",
    "    # cv means cross-validation\n",
    "    # n_jobs means the cucurrent number of jobs\n",
    "    grid_s = GridSearchCV(pipeline, parameters, cv=10, verbose=3, n_jobs=2, scoring='roc_auc')\n",
    "    grid_s.fit(X, Y) # used to fit the model \n",
    "\n",
    "    # to show the best score and the best hyperparameters\n",
    "    print('The Best Score : ',grid_s.best_score_)\n",
    "    print('The Best Hyperparameter : ',grid_s.best_params_)\n",
    "\n",
    "    # to creat the CSV file, we will call the function csv_creator\n",
    "    CSV_creator(model_name,grid_s)\n",
    "                    \n",
    "#___________________________Randrom Search Function__________________________________________________________\n",
    "                    \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "def random_search_fun(pipeline, parameters, model_name, itr):\n",
    "    random_s = RandomizedSearchCV(pipeline, parameters, verbose=1, cv=10, n_iter=itr, n_jobs=2, scoring='roc_auc')\n",
    "    random_s.fit(X, Y)\n",
    "\n",
    "    print('The Best Score : ',random_s.best_score_)\n",
    "    print('The Best Hyperparameter : ',random_s.best_params_)\n",
    "\n",
    "    CSV_creator(model_name,random_s)                    \n",
    "                    \n",
    "#___________________________Bayesian Search Function_________________________________________________________\n",
    "                    \n",
    "from skopt import BayesSearchCV\n",
    "def bayesian_search_fun(pipeline, parameters, model_name, itr):\n",
    "    bayesian_s = BayesSearchCV(pipeline, parameters, cv=10, n_iter=itr, verbose=3, n_jobs=2, scoring='roc_auc')\n",
    "    bayesian_s.fit(X, Y)\n",
    "\n",
    "    print('The Best Score : ' , bayesian_s.best_score_)\n",
    "    print('The Best Hyperparameter : ' , bayesian_s.best_params_)\n",
    "\n",
    "    CSV_creator(model_name,bayesian_s)                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For creating pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "# pipeline for numeric features preprocessing\n",
    "# SimpleImputer:Univariate imputer for completing missing values with simple strategies.\n",
    "# Standardize features by removing the mean and scaling to unit variance.\n",
    "pip_numeric = Pipeline(\n",
    "    steps=[ ('imputer', SimpleImputer()),\n",
    "            ('scaler', StandardScaler())])\n",
    "#_______________________________________________________________________________\n",
    "\n",
    "# pipeline for categorical features preprocessing\n",
    "# OneHotEncoder:Encode categorical features as a one-hot numeric array.\n",
    "pip_categorical = Pipeline(\n",
    "    steps=[ ('imputer', SimpleImputer(strategy='constant')),\n",
    "            ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "#_______________________________________________________________________________\n",
    "\n",
    "# define preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[ ('num', pip_numeric, Numeric_features),\n",
    "                    ('cat', pip_categorical, Cat_features)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Creating the classifiers and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_______________________________XGBClassifier__________________________________________________\n",
    "XGB = XGBClassifier(  scale_pos_weight=1, \n",
    "                      colsample_bytree = 0.4,\n",
    "                      learning_rate=0.02,\n",
    "                        max_depth=11,\n",
    "                      n_estimators=900,\n",
    "                      subsample = 0.8,\n",
    "                      objective='binary:logistic',\n",
    "                      seed = 2,\n",
    "                      reg_alpha = 0.3)\n",
    "\n",
    "XGB_params = {\n",
    " 'preprocessor__num__imputer__strategy': ['mean','median'],\n",
    "  # wider range for number of estimators in the ensemble\n",
    " 'my_classifier__n_estimators': [100,200,500], \n",
    " 'my_classifier__max_depth':[5,7,10,15],\n",
    " 'my_classifier__subsample':[0.6,0.8,1],\n",
    " 'my_classifier__colsample_bytree':[0.5,0.7,1]\n",
    " }\n",
    "\n",
    "#______________________________GradientBoostingClassifier________________________________________\n",
    "\n",
    "GBC = GradientBoostingClassifier(min_samples_split=500,\n",
    "                                 subsample=0.8,\n",
    "                                 random_state=42,\n",
    "                                 max_depth=11,\n",
    "                                 n_estimators=900,\n",
    "                                 learning_rate=0.02)\n",
    "\n",
    "GBC_param = {\n",
    "      'preprocessor__num__imputer__strategy': ['mean'], \n",
    "      'my_classifier__max_depth':[6,8,10] ,\n",
    "      'n_estimators':range(20,81,10)   \n",
    "}\n",
    "#_____________________________ExtraTreesClassifier_______________________________________________\n",
    "ETC = ExtraTreesClassifier(n_estimators=900,\n",
    "                           n_jobs=4,\n",
    "                           min_samples_split=25,\n",
    "                            min_samples_leaf=35)\n",
    "\n",
    "ETC_params = {\n",
    "      'preprocessor__num__imputer__strategy': ['mean','median'], \n",
    "      'my_classifier__max_depth':[11,12,13] ,\n",
    "  \n",
    "}\n",
    "\n",
    "#_____________________________RandomForestClassifier_______________________________________________\n",
    "\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "# using a wider range of parameters in this grid\n",
    "RFC_params = {\n",
    " # trying different numeric imputation strategies, initial in template is 'median'\n",
    " # 'most_frequent' is the mode for a given feature\n",
    " 'preprocessor__num__imputer__strategy': ['mean','median', 'most_frequent'],\n",
    " # wider range for number of estimators in the ensemble\n",
    " 'my_classifier__n_estimators': [10,20,30,40,50,100],\n",
    " # wider range for maximum tree depth\n",
    " 'my_classifier__max_depth':[5,10,20,30,50],\n",
    " # trying different criteria for measuring impurity\n",
    " 'my_classifier__criterion':['gini','entropy'],\n",
    " # varying the number of features to include when computing the best split\n",
    " 'my_classifier__max_features':['auto','sqrt','log2'],\n",
    " # assigning balanced weights to each class to handle imbalanced target\n",
    " # subsample computes weights based on each bootstrap sample or 'bag' \n",
    " 'my_classifier__class_weight':['balanced','balanced_subsample']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------------------------------------XGBClassifier--------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For using XGBClassifier using Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the preprocessor with the model as a full tunable pipeline\n",
    "full_pipline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "         ('selector', SelectKBest(mutual_info_classif, k=125)),\n",
    "        ('my_classifier', XGB)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Score :  0.8877654036272784\n",
      "The Best Hyperparameter :  {'preprocessor__num__imputer__strategy': 'mean', 'my_classifier__subsample': 0.6, 'my_classifier__n_estimators': 500, 'my_classifier__max_depth': 7, 'my_classifier__colsample_bytree': 1}\n"
     ]
    }
   ],
   "source": [
    "random_search_fun(full_pipline, XGB_params, 'XGBClassifier_RS', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For using XGBClassifier using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 216 candidates, totalling 2160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   28.6s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:  6.7min\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed: 15.0min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed: 27.1min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed: 39.0min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed: 59.3min\n",
      "[Parallel(n_jobs=2)]: Done 2044 tasks      | elapsed: 83.1min\n",
      "[Parallel(n_jobs=2)]: Done 2160 out of 2160 | elapsed: 93.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Score :  0.8880124727465726\n",
      "The Best Hyperparameter :  {'my_classifier__colsample_bytree': 1, 'my_classifier__max_depth': 7, 'my_classifier__n_estimators': 500, 'my_classifier__subsample': 0.8, 'preprocessor__num__imputer__strategy': 'mean'}\n"
     ]
    }
   ],
   "source": [
    "grid_search_fun(full_pipline, XGB_params, 'XGBClassifier_GS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For using XGBClassifier using bayesian search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   40.6s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   22.0s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   16.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   19.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   15.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   33.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   38.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   24.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   37.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   48.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Score :  0.8880124727465726\n",
      "The Best Hyperparameter :  OrderedDict([('my_classifier__colsample_bytree', 1.0), ('my_classifier__max_depth', 7), ('my_classifier__n_estimators', 500), ('my_classifier__subsample', 0.8), ('preprocessor__num__imputer__strategy', 'mean')])\n"
     ]
    }
   ],
   "source": [
    "bayesian_search_fun(full_pipline, XGB_params, 'XGBClassifier_BS', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------------------------------------GradientBoostingClassifier--------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **For using GradientBoostingClassifier using Random search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the preprocessor with the model as a full tunable pipeline\n",
    "full_pipline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "         ('selector', SelectKBest(mutual_info_classif, k=125)),\n",
    "        ('my_classifier', GBC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  30 out of  30 | elapsed: 26.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Score :  0.8870631656507614\n",
      "The Best Hyperparameter :  {'preprocessor__num__imputer__strategy': 'mean', 'my_classifier__max_depth': 8}\n"
     ]
    }
   ],
   "source": [
    "random_search_fun(full_pipline, GBC_param, 'GradientBoostingClassifier_RS', 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For using GradientBoostingClassifier using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 3 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  30 out of  30 | elapsed: 26.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Score :  0.8870631656507614\n",
      "The Best Hyperparameter :  {'my_classifier__max_depth': 8, 'preprocessor__num__imputer__strategy': 'mean'}\n"
     ]
    }
   ],
   "source": [
    "grid_search_fun(full_pipline, GBC_param, 'GradientBoostingClassifier_GS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For using GradientBoostingClassifier using bayesian search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:  8.9min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:  7.0min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:  8.9min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:  7.1min finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed: 16.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Score :  0.8870631656507614\n",
      "The Best Hyperparameter :  OrderedDict([('my_classifier__max_depth', 8), ('preprocessor__num__imputer__strategy', 'mean')])\n"
     ]
    }
   ],
   "source": [
    "bayesian_search_fun(full_pipline, GBC_param, 'GradientBoostingClassifier_BS', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------------------------ExtraTreesClassifier---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **For using ExtraTreesClassifier using Random search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the preprocessor with the model as a full tunable pipeline\n",
    "full_pipline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "         ('selector', SelectKBest(mutual_info_classif, k=125)),\n",
    "        ('my_classifier', ETC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Score :  0.8632085790029581\n",
      "The Best Hyperparameter :  {'preprocessor__num__imputer__strategy': 'mean', 'my_classifier__max_depth': 11}\n"
     ]
    }
   ],
   "source": [
    "random_search_fun(full_pipline, ETC_params, 'ExtraTreesClassifier_RS', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For using ExtraTreesClassifier using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 6 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=2)]: Done  60 out of  60 | elapsed:  4.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Score :  0.8638499061644351\n",
      "The Best Hyperparameter :  {'my_classifier__max_depth': 13, 'preprocessor__num__imputer__strategy': 'mean'}\n"
     ]
    }
   ],
   "source": [
    "grid_search_fun(full_pipline, ETC_params, 'ExtraTreesClassifier_GS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For using ExtraTreesClassifier using bayesian search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   52.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   48.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   52.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   48.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   51.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   48.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   52.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   45.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   52.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   45.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Score :  0.8636177109339714\n",
      "The Best Hyperparameter :  OrderedDict([('my_classifier__max_depth', 12), ('preprocessor__num__imputer__strategy', 'mean')])\n"
     ]
    }
   ],
   "source": [
    "bayesian_search_fun(full_pipline, ETC_params, 'ExtraTreesClassifier_BS', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------------------------RandomForestClassifier---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For using RandomForestClassifier using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the preprocessor with the model as a full tunable pipeline\n",
    "full_pipline = Pipeline(\n",
    "    steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "         ('selector', SelectKBest(mutual_info_classif, k=125)),\n",
    "        ('my_classifier', RFC)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1080 candidates, totalling 10800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=2)]: Done 124 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=2)]: Done 284 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=2)]: Done 508 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed: 14.6min\n",
      "[Parallel(n_jobs=2)]: Done 1148 tasks      | elapsed: 22.7min\n",
      "[Parallel(n_jobs=2)]: Done 1564 tasks      | elapsed: 34.9min\n",
      "[Parallel(n_jobs=2)]: Done 2044 tasks      | elapsed: 49.2min\n",
      "[Parallel(n_jobs=2)]: Done 2588 tasks      | elapsed: 81.7min\n",
      "[Parallel(n_jobs=2)]: Done 3196 tasks      | elapsed: 92.6min\n",
      "[Parallel(n_jobs=2)]: Done 3868 tasks      | elapsed: 114.0min\n",
      "[Parallel(n_jobs=2)]: Done 4604 tasks      | elapsed: 135.5min\n",
      "[Parallel(n_jobs=2)]: Done 5404 tasks      | elapsed: 159.2min\n",
      "[Parallel(n_jobs=2)]: Done 6268 tasks      | elapsed: 176.1min\n",
      "[Parallel(n_jobs=2)]: Done 7196 tasks      | elapsed: 203.0min\n",
      "[Parallel(n_jobs=2)]: Done 8188 tasks      | elapsed: 230.9min\n",
      "[Parallel(n_jobs=2)]: Done 9244 tasks      | elapsed: 252.1min\n",
      "[Parallel(n_jobs=2)]: Done 10364 tasks      | elapsed: 284.8min\n",
      "[Parallel(n_jobs=2)]: Done 10800 out of 10800 | elapsed: 298.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Score :  0.8727903727223915\n",
      "The Best Hyperparameter :  {'my_classifier__class_weight': 'balanced_subsample', 'my_classifier__criterion': 'entropy', 'my_classifier__max_depth': 30, 'my_classifier__max_features': 'auto', 'my_classifier__n_estimators': 100, 'preprocessor__num__imputer__strategy': 'mean'}\n"
     ]
    }
   ],
   "source": [
    "grid_search_fun(full_pipline, RFC_params, 'RandomForestClassifier_GS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **For using RandomForestClassifier using Random search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  28 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=2)]: Done 100 out of 100 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Score :  0.8653452836266142\n",
      "The Best Hyperparameter :  {'preprocessor__num__imputer__strategy': 'median', 'my_classifier__n_estimators': 100, 'my_classifier__max_features': 'sqrt', 'my_classifier__max_depth': 30, 'my_classifier__criterion': 'entropy', 'my_classifier__class_weight': 'balanced_subsample'}\n"
     ]
    }
   ],
   "source": [
    "random_search_fun(full_pipline, RFC_params, 'RandomForestClassifier_RS', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **For using RandomForestClassifier using bayesian search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   28.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   15.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   14.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   17.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   36.3s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   26.8s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   16.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   12.9s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:   21.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  10 out of  10 | elapsed:    9.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Best Score :  0.8642856566427236\n",
      "The Best Hyperparameter :  OrderedDict([('my_classifier__class_weight', 'balanced_subsample'), ('my_classifier__criterion', 'gini'), ('my_classifier__max_depth', 20), ('my_classifier__max_features', 'sqrt'), ('my_classifier__n_estimators', 100), ('preprocessor__num__imputer__strategy', 'median')])\n"
     ]
    }
   ],
   "source": [
    "bayesian_search_fun(full_pipline, RFC_params, 'RandomForestClassifier_BS', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- ✔️ Answer some of questions (briefly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------------------The Questions---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 🌈Why a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?\n",
    "* 🌈What's a decision tree and how it is different to a logistic regression model?\n",
    "* 🌈What's the difference between grid search and random search?\n",
    "* 🌈What's the difference between bayesian search and random search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------------------Answer The Questions---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 🌈Why a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A simple linear regression model without any activation function is not well-suited for classification tasks for several reasons:**\n",
    "\n",
    "*    1) Output range: Linear regression models predict a continuous output variable, which can take any value on the real number line. In contrast, for binary classification tasks (e.g. classifying images as cat or not cat), the output should be a binary value (0 or 1). For multi-class classification tasks (e.g. classifying images into several categories), the output should be categorical, with each category corresponding to a unique value.\n",
    "\n",
    "*    2) Sensitivity to outliers: Linear regression models are sensitive to outliers, meaning that they can be heavily influenced by data points that are far from the main cluster of data. This can cause the model to predict extreme values, which may not be suitable for classification tasks where the output values should be well-defined.\n",
    "\n",
    "*    3) Non-linear decision boundaries: Linear regression models fit a straight line to the data, which may not be flexible enough to capture complex decision boundaries in classification tasks. For example, consider a dataset where the two classes are separated by a curved boundary. A linear regression model may not be able to capture this curved boundary and would perform poorly on this task.\n",
    "\n",
    "**Perceptron and logistic regression models, on the other hand, are specifically designed for classification tasks and address these limitations:**\n",
    "\n",
    "*    1) Output range: Perceptron and logistic regression models use an activation function to map the output to a specific range (e.g. sigmoid function maps the output to the range [0, 1]). This ensures that the output is appropriate for classification tasks.\n",
    "\n",
    "*    2) Robustness to outliers: Perceptron and logistic regression models are less sensitive to outliers compared to linear regression models. This is because the activation function limits the output range, and the optimization algorithm focuses on minimizing the classification error rather than the residual error.\n",
    "\n",
    "*    3) Non-linear decision boundaries: Perceptron and logistic regression models can use non-linear activation functions to model complex decision boundaries. For example, a neural network with multiple layers and non-linear activation functions can capture highly complex decision boundaries.\n",
    "\n",
    "**Overall, a simple linear regression model is not a suitable choice for classification tasks due to its limitations. Perceptron and logistic regression models, on the other hand, are specifically designed for classification tasks and are more appropriate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🌈What's a decision tree and how it is different to a logistic regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A decision tree is a type of supervised learning algorithm used in machine learning and data mining. It is a hierarchical model that recursively splits the dataset into subsets based on the most important features, with each split aiming to maximize the difference in outcome between the resulting subsets. At each node of the tree, a decision is made based on a feature value to move to the next node, until a leaf node is reached that corresponds to a predicted outcome.\n",
    "\n",
    "* In contrast, logistic regression is a type of statistical model used to model the probability of a binary outcome (e.g. yes/no or 0/1). Logistic regression models the relationship between the dependent variable and one or more independent variables, using a logistic function to map the linear output of the model to a probability score.\n",
    "\n",
    "**The main differences between decision trees and logistic regression models are as follows:**\n",
    "\n",
    "* Model structure: Decision trees are hierarchical models, consisting of a root node, internal nodes, and leaf nodes, whereas logistic regression is a linear model that uses a logistic function to map the output to a probability score.\n",
    "\n",
    "* Interpretability: Decision trees are highly interpretable, as they can be visualized and easily understood by non-technical users. Logistic regression models are less interpretable, as the relationship between the independent variables and the dependent variable is modeled as a linear combination of coefficients, which may not be easily understood.\n",
    "\n",
    "* Non-linear relationships: Decision trees are able to model non-linear relationships between the dependent variable and the independent variables by recursively splitting the data based on the most important features. Logistic regression models assume a linear relationship between the independent variables and the dependent variable, unless non-linear terms or interactions are explicitly included in the model.\n",
    "\n",
    "* Overfitting: Decision trees are prone to overfitting the data, especially if the tree is too complex or if the data has a lot of noise. Logistic regression models are less prone to overfitting and are generally more robust, especially if regularization techniques are used.\n",
    "\n",
    "**In summary, decision trees and logistic regression models are both popular supervised learning algorithms, but differ in their model structure, interpretability, ability to model non-linear relationships, and tendency to overfit the data. The choice of which model to use depends on the specific characteristics of the data and the modeling objectives.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🌈What's the difference between grid search and random search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Grid search and random search are two commonly used hyperparameter optimization techniques used in machine learning. Both methods are used to search for the best set of hyperparameters for a given machine learning model, but they differ in their search strategy.\n",
    "\n",
    "* Grid search is a method where a pre-defined set of hyperparameters is selected, and the model is trained on all possible combinations of hyperparameters in a grid-like manner. The search is typically guided by a predefined range of values for each hyperparameter, and each combination is evaluated by a cross-validation procedure to estimate its performance on unseen data. Grid search is a systematic approach to hyperparameter optimization that exhaustively searches all possible combinations of hyperparameters, and it is suitable for cases where the search space is small and the computational cost is affordable.\n",
    "\n",
    "* In contrast, random search is a method where hyperparameters are randomly sampled from a pre-defined range of values, and the model is trained on a random subset of these combinations. Random search is a more flexible approach that can explore a wider range of hyperparameters and does not require predefining a grid-like search space. It can be computationally cheaper than grid search, especially when the search space is large.\n",
    "\n",
    "**The main differences between grid search and random search are:**\n",
    "\n",
    "1) Search strategy: Grid search searches all possible combinations of hyperparameters, while random search selects hyperparameters randomly.\n",
    "\n",
    "2) Computation cost: Grid search can be computationally expensive, especially when the search space is large, while random search is typically less expensive.\n",
    "\n",
    "3) Search space: Grid search requires a pre-defined search space for hyperparameters, while random search only requires a range of values for each hyperparameter.\n",
    "\n",
    "4) Performance: Grid search can guarantee finding the optimal combination of hyperparameters if the search space is small and the performance metric is well-defined, while random search is less guaranteed to find the optimal combination, but can still perform well, especially if the search space is large.\n",
    "\n",
    "**In summary, grid search and random search are two widely used hyperparameter optimization techniques, each with its own advantages and disadvantages. Grid search is more systematic and can guarantee finding the optimal combination, while random search is more flexible and less computationally expensive, but may not guarantee finding the optimal combination. The choice of which method to use depends on the specific characteristics of the problem, the size of the search space, and the computational resources available.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🌈What's the difference between bayesian search and random search?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Both Bayesian search and random search are methods used for hyperparameter tuning in machine learning models. The main difference between the two approaches is the way they explore the hyperparameter space.\n",
    "\n",
    "* Random search selects hyperparameters randomly from a given search space. It doesn't use any prior knowledge about the performance of the model on the dataset. Therefore, it requires a larger number of iterations to find the optimal hyperparameters, as compared to other methods.\n",
    "\n",
    "* Bayesian search, on the other hand, uses probability distributions to select hyperparameters. It uses prior knowledge about the performance of the model on the dataset to update the probability distribution of the hyperparameters after each iteration. This helps to select the most promising hyperparameters based on the previous results, which can lead to a faster convergence to the optimal hyperparameters.\n",
    "\n",
    "**In summary, random search is a simpler and more straightforward method for hyperparameter tuning, but it may require a larger number of iterations to find the optimal hyperparameters. Bayesian search is a more complex method that requires more computational resources, but it can converge to the optimal hyperparameters faster by leveraging previous results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
